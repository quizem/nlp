{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title: Words - Getting Started with NLP\n",
    "##### Author: Amo\n",
    "<strong>email:</strong> kwaby.dad@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction:\n",
    "The first steps with natural language processing lie with understanding the basic units of text data â€“ words. Because for any single document, words (in various forms) are combined to develop an idea or a concept. In this workbook, I demonstrate how you can take any arbitrary piece of text and extract tokens for further. I also introduce some powerful nlp tools that you can deploy in performing tasks as simple as tokenization to even more sophisticated ones such as dependency parsing, named entity extraction etc\n",
    "<br>\n",
    "<br><strong>Goal: </strong> Get a basic understanding of text preprocessing\n",
    "<br>\n",
    "\n",
    "Approach:\n",
    "* manual approach\n",
    "* using specialized modules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Get data\n",
    "<strong> Data Description:</strong>\n",
    "* The text used here is a very short but interesting one about insects. It's quite simple and that's why I used it for this demo.\n",
    "* source: https://breakingnewsenglish.com/1907/190716-insect-pain.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['## title: insects can feel pain\\n',\n",
       " '## source: https://breakingnewsenglish.com/1907/190716-insect-pain.html\\n',\n",
       " 'New research shows that insects feel pain. The researchers say it isn\\'t the same kind of pain that humans feel. The pain that insects feel is a sensation that is like pain. The research was conducted at the University of Sydney in Australia. Professor Greg Neely, co-author of the research report, said: \"People don\\'t really think of insects as feeling any kind of pain, but it\\'s already been shown in lots of different invertebrate animals that they can sense and avoid dangerous [things] that we [think of] as painful.\" He added: \"We knew that insects could sense \\'pain\\' but what we didn\\'t know is that an injury could lead to long-lasting hyper-sensitivity...in a similar way to human patients\\' experiences.\"\\n',\n",
       " 'The researchers looked at how fruit flies reacted to injuries. The scientists damaged one leg on the flies and allowed the leg to heal. They found that after the leg fully healed, the flies became more sensitive and tried harder to protect their legs. Professor Neely said the pain the flies felt stayed in their memory and this changed their behaviour. He said: \"After the [insect] is hurt once badly, they are hypersensitive and try to protect themselves for the rest of their lives.\" Neely says he hopes to carry out more research to better understand how humans feel pain. He said: \"We are focused on making new stem cell therapies or drugs that target the underlying cause and stop pain for good.\"']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "with open('insects.txt','r') as inf:\n",
    "    raw_text = inf.readlines()\n",
    "    \n",
    "    \n",
    "# preview what's in the first few lines of the file\n",
    "\n",
    "raw_text[:5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokenize text\n",
    "* <strong>Goal:</strong> As you can see, the text about is stored as list of lines. It's because that's how we read in our\n",
    "data. We can eaasily change it from a list into one long string of text as folow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New research shows that insects feel pain. The researchers say it isn\\'t the same kind of pain that humans feel. The pain that insects feel is a sensation that is like pain. The research was conducted at the University of Sydney in Australia. Professor Greg Neely, co-author of the research report, said: \"People don\\'t really think of insects as feeling any kind of pain, but it\\'s already been shown in lots of different invertebrate animals that they can sense and avoid dangerous [things] that we [think of] as painful.\" He added: \"We knew that insects could sense \\'pain\\' but what we didn\\'t know is that an injury could lead to long-lasting hyper-sensitivity...in a similar way to human patients\\' experiences.\"\\nThe researchers looked at how fruit flies reacted to injuries. The scientists damaged one leg on the flies and allowed the leg to heal. They found that after the leg fully healed, the flies became more sensitive and tried harder to protect their legs. Professor Neely said the pain the flies felt stayed in their memory and this changed their behaviour. He said: \"After the [insect] is hurt once badly, they are hypersensitive and try to protect themselves for the rest of their lives.\" Neely says he hopes to carry out more research to better understand how humans feel pain. He said: \"We are focused on making new stem cell therapies or drugs that target the underlying cause and stop pain for good.\"'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = raw_text[2:] # exlude the first 2 lines as they are just meta data\n",
    "raw_string = ''.join(raw_text)\n",
    "raw_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "<hr>\n",
    "The above conversion may seem trivial at this point, and in fact it doesn't really matter now. How you chose to present\n",
    "your text data will depend on the use in mind. However in the next tast we'll use the raw_string version for convenience\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A. Simple Whitespace tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick online reference: <a href='https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization'>Tokenization</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New',\n",
       " 'research',\n",
       " 'shows',\n",
       " 'that',\n",
       " 'insects',\n",
       " 'feel',\n",
       " 'pain.',\n",
       " 'The',\n",
       " 'researchers',\n",
       " 'say',\n",
       " 'it',\n",
       " \"isn't\",\n",
       " 'the',\n",
       " 'same',\n",
       " 'kind']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we perform a simple tokenization based on whitespaces between words:\n",
    "\n",
    "tokenized_text = raw_string.split(' ') # split string on whaitespaces\n",
    "tokenized_text[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes: \n",
    "<hr>\n",
    "Now we have a list of tokens ready for further processing. We can do the same using nltk module, which use more advanced \n",
    "rules to generate token. let's try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B. Tokenization using advanced tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New',\n",
       " 'research',\n",
       " 'shows',\n",
       " 'that',\n",
       " 'insects',\n",
       " 'feel',\n",
       " 'pain',\n",
       " '.',\n",
       " 'The',\n",
       " 'researchers',\n",
       " 'say',\n",
       " 'it',\n",
       " 'is',\n",
       " \"n't\",\n",
       " 'the']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_tokens  =  word_tokenize(raw_string,language='english')\n",
    "nltk_tokens[:15] #preview first 10 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "<hr>\n",
    "There is a clear difference in the outputs from our previous tokenization and the one we've done using nltk. It follows conventions specified by the <a href='ftp://ftp.cis.upenn.edu/pub/treebank/public_html/tokenization.html'>treebank</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Further Operations on words\n",
    "Unless your goal is just to do simple word counts of frequencies, most language processing tasks will require additional\n",
    "operations on tokens to provide more context on what tokens actually represnt in the text. Some of the common steps include:\n",
    "- Part of speech (POS) tagging\n",
    "- Lemmatization\n",
    "- Stemming\n",
    "\n",
    "In the following lines, I'll demonstrate what a POS tagged text looks like and also perform a quick lemmatization task (you can use stemming or lemmatization to reduce words to their common denominator. I prefer to use word lammas)\n",
    "\n",
    "#### Online reference: <a href='https://en.wikipedia.org/wiki/Lemmatisation'>Lemmatization</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "<hr>\n",
    "We use spacy, an advance LNP tool for demonstration here. We first load the module an initialize the pretrained English\n",
    "language model. we disable a few of the steps in the processing pipeline since we won't need it at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # we'll store our results in data frame just for presentation purposes\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en',disable=['ner','parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>lemma</th>\n",
       "      <th>Part of Speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New</td>\n",
       "      <td>new</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>research</td>\n",
       "      <td>research</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shows</td>\n",
       "      <td>show</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insects</td>\n",
       "      <td>insect</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feel</td>\n",
       "      <td>feel</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pain</td>\n",
       "      <td>pain</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>researchers</td>\n",
       "      <td>researcher</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      original       lemma Part of Speech\n",
       "0          New         new            ADJ\n",
       "1     research    research           NOUN\n",
       "2        shows        show           VERB\n",
       "3         that        that            ADP\n",
       "4      insects      insect           NOUN\n",
       "5         feel        feel           VERB\n",
       "6         pain        pain           NOUN\n",
       "7            .           .          PUNCT\n",
       "8          The         the            DET\n",
       "9  researchers  researcher           NOUN"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we first create a spacy doc that will automatically parse our text and do a lot for us behind the scenes\n",
    "\n",
    "doc = nlp(raw_string)\n",
    "token_info = [(token.text,token.lemma_,token.pos_) for token in doc]\n",
    "\n",
    "token_df = pd.DataFrame(token_info,columns=['original','lemma','Part of Speech'])\n",
    "token_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save datframe output\n",
    "token_df.to_csv('token_df.csv')\n",
    "\n",
    "# save text\n",
    "## I like using json format to structure data for storing. There are many options for saving your text though\n",
    "\n",
    "data ={'title':'insects can feel pain',\n",
    "     'source':'https://breakingnewsenglish.com/1907/190716-insect-pain.html',\n",
    "     'content':raw_string}\n",
    "with open('text.json','w') as out:\n",
    "    json.dump(data,out)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this notebook I demonstrate how to kickstart an NLP task by understanding what makes up a huge body of text. I also introduce some advanced tools to help you perform simple to advance language processing tasks. In future notebooks, I'll show to perform additional text preprocessing and how to turn a piece text into a neat body of knowledge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
